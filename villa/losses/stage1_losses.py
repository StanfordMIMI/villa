import torch
import numpy as np
from villa.losses.default import BaseLoss


class Stage1_Loss(BaseLoss):
    def __init__(self, temp: float, one_proj: bool, data_dir: str):
        """
        Initialize loss function for ViLLA Stage 1.

        Parameters:
            temp (float): Loss temperature parameter
            one_proj (bool): True if using one projection head, False otherwise
            data_dir (str): Filepath to directory with data
        """
        super().__init__()

        # Initialize class variables
        self.temperature = temp
        self.one_proj = one_proj

        # Load attribute embeddings
        attr_to_embs = torch.load(f"{data_dir}/attr_embs.pth")
        self.attr_embs = []
        for a in attr_to_embs:
            self.attr_embs.append(attr_to_embs[a])
        self.attr_embs = torch.tensor(np.stack(self.attr_embs)).cuda().to(torch.float32)

    def forward(self, pred: dict, sample: dict):
        """
        Compute loss function for ViLLA Stage 1.

        Parameters:
            pred (dict): Predictions generated by model
            sample (dict): Data associated with each sample
        Returns:
            loss (torch.Tensor): Final loss value
        """
        # Initialize region embeddings and attribute labels
        anchor_img = torch.nn.functional.normalize(
            pred["region_proj_embs"].float(), dim=2
        )
        labels = sample["attr_labels"].to(int)
        attr_ids = labels.sum(0).nonzero().flatten().tolist()
        batch_size = labels.shape[0]

        loss = torch.tensor(0.0).cuda()
        num_loss_terms = 0

        # Compute region-attribute similarity matrix by calculating the similarity between
        # each attribute and the region embedding resulting from the corresponding projection head
        if self.one_proj:
            txt_emb = self.attr_embs[attr_ids, :].T.unsqueeze(0)
            sim = (anchor_img @ txt_emb).squeeze() / self.temperature
        else:
            reg_emb = anchor_img[:, attr_ids, :]
            txt_emb = self.attr_embs[attr_ids, :].unsqueeze(0)
            sim = (reg_emb * txt_emb).sum(2) / self.temperature

        # Convert region-attribute similarity matrix into image-attribute similarity matrix by
        # computing the maximum pairwise similarity between all regions in the image and each attribute
        split = torch.split(sim, sample["num_regions"].tolist(), dim=0)
        vals, _ = zip(*map(torch.max, split, [0] * batch_size))
        sim = torch.stack(vals)  # Size: batch_size x len(attr_ids)

        true_label = labels[:, attr_ids].cuda()
        inv_true_label = (~true_label.bool()).to(int)

        # Compute final contrastive loss
        denom = torch.exp(sim) + torch.exp(sim * inv_true_label).sum(0, keepdims=True)
        loss = ((-torch.log(torch.exp(sim) / denom)) * true_label).sum(1, keepdims=True)
        num_loss_terms = true_label.sum()
        loss = loss.sum() / num_loss_terms

        self.update_running_loss(loss)
        return loss
